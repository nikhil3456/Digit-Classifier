{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Instruction\n",
    "\n",
    "- When you are coding neural network don't use data-structures where the shape is like (n,) i.e rank-1 array.\n",
    "- This rank-1 array are niether row vector nor column vector.\n",
    "- If you want to use array in code use a=np.random.randn(5,1) or a=np.random.randn(1,5)\n",
    "- Instead set an vector like a = np.random.randn(5,1) not like np.random.randn(5,1)\n",
    "- There is a difference when using the above method you will see two square brackets like ]]  instead of ] in np.random.randn(5).\n",
    "- Use assert statements to in code for dimension checking like assert(a.shape == (5,1))\n",
    "- If rank-1 array is created use a = a.reshape((5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from subprocess import check_output\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize params and layer sizes\n",
    "def init_parameters_and_layer_sizes_NN(x_train, y_train):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps for making a L-layer neural-net\n",
    "- Load the dataset\n",
    "- Split the dataset into train and test\n",
    "- Convert the data (resize) so as to serve as input to the input layer of neural net\n",
    "- Initialise weight matrix and bias matrix for differernt layers\n",
    "  - set the hyperparameters: number of layers, number of units in each layer, learning rate\n",
    "- define the activation functions for hidden layers and output layer, loss function\n",
    "- define and init the activation function for different layers\n",
    "- define the cost function\n",
    "- Write forward and backward propagation functions\n",
    "- write the update function (for updating params like W martix for each layer)\n",
    "  - Include gradient descent\n",
    "- Prediction function for predicting output on given data\n",
    "- Function for calling all other function and getting and comparing output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1649, 4096)\n",
      "(413, 4096)\n"
     ]
    }
   ],
   "source": [
    "#### Load the data\n",
    "X_data = np.load('../input/Sign-language-digits-dataset/X.npy')\n",
    "Y_data = np.load('../input/Sign-language-digits-dataset/Y.npy')\n",
    "X = X_data.reshape((2062, 4096)) # Input\n",
    "Y = Y_data.reshape((2062, 10)) # Ground truth value\n",
    "\n",
    "### split into train and test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 42)\n",
    "\n",
    "\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Constructing the params for the input layer\n",
    "X_train = X_train.reshape((4096, 1649))\n",
    "Y_train = Y_train.reshape((10, 1649))\n",
    "X_test = X_test.reshape((4096, 413))\n",
    "Y_test = Y_test.reshape((10, 413))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function initializes weight matrix and bias matrix for each layer\n",
    "'''\n",
    "    L is no. of layers\n",
    "    n is an LX1 vector where n[i] = number of units in layer i\n",
    "    init_wt is the initial value of weight parameters\n",
    "    init_b is the initial value of bias parameter\n",
    "\n",
    "'''\n",
    "def init_params_and_layer_sizes_NN(X_train, Y_train, L, n, init_wt, init_b):\n",
    "    params = {}\n",
    "    for i in range(L):\n",
    "        params['W%i' %(i+1)] = np.full((n[i+1][0], n[i][0]), init_wt)\n",
    "        params['b%i' %(i+1)] = np.full((n[i+1][0], 1), init_b)\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the activation function for hidden layer\n",
    "# We will use RELU for hidden layers\n",
    "def relu(Z):\n",
    "    Z = np.maximum(Z, 0)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the activation function for output layer\n",
    "# We will use Softmax for output-layer as this is the multi-class classification problem\n",
    "def softmax(Z):\n",
    "    Z = Z - np.max(Z)\n",
    "    Z = np.exp(Z)\n",
    "    ax_sum = np.sum(Z, axis=0)\n",
    "    ax_sum = ax_sum.reshape((1, Z.shape[1]))\n",
    "    Z = Z/ax_sum\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is for computing the cost function\n",
    "# We used Cross-entropy loss\n",
    "# For cost function see: https://datascience.stackexchange.com/questions/20296/cross-entropy-loss-explanation\n",
    "def compute_cost_NN(AN, Y):\n",
    "    'AN is the output of output layer and Y is the Ground truth output'\n",
    "    N = AN.shape[1] # N = no_of_samples\n",
    "    loss = np.sum(AN*Y, axis = 0) # each element of this matrix give the loss of corresponding sample\n",
    "    return ((-1/N)*(np.sum(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagation\n",
    "def forward_propagation_NN(X_train, params, L):\n",
    "    'L is the number of layers in the NN'\n",
    "    cache = {} \n",
    "    A = X_train\n",
    "    cache['Z%i' %(0)] = []\n",
    "    cache['A%i' %(0)] = A\n",
    "    for i in range(L):\n",
    "        l = i+1 # l is the layer number\n",
    "        Z = np.dot(params['W%i' %(l)], A) + params['b%i' %(l)]\n",
    "        if (l!=L): A = relu(Z)\n",
    "        else: A = softmax(Z)\n",
    "        cache['Z%i' %(l)] = Z\n",
    "        cache['A%i' %(l)] = A\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reluDerivative(Z):\n",
    "    Z[Z<=0] = 0\n",
    "    Z[Z>0] = 1\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax-gradient: https://datascience.stackexchange.com/questions/29735/how-to-apply-the-gradient-of-softmax-in-backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward propagation\n",
    "def backward_propagation_NN(params, cache, X_train, Y_train, L):\n",
    "    'L is the number of layers in NN'\n",
    "    \n",
    "    # First I will define dZ, dW, db for layer L i.e output layer:\n",
    "    grads = {}\n",
    "    dZ = cache[\"A%i\" %(L)] - Y_train\n",
    "    N = Y_train.shape[1] # N denotes number of samples\n",
    "    dW = (1/N)*(np.dot(dZ, (cache[\"A%i\" %(L-1)]).T))\n",
    "    db = (1/N)*(np.sum(dZ, axis=1, keepdims=True))\n",
    "    \n",
    "    grads[\"dW%i\" %(L)] = dW\n",
    "    grads[\"db%i\" %(L)] = db\n",
    "    \n",
    "    for i in range(L-1, 0, -1):\n",
    "        l = i # l denotes the layer number\n",
    "        dZ = np.dot((params[\"W%i\" %(l+1)].T), dZ)\n",
    "        Zl = cache[\"Z%i\" %(l)]\n",
    "        dZ = dZ * (reluDerivative(Zl))\n",
    "        dW = (1/N)*(np.dot(dZ, (cache[\"A%i\" %(l-1)].T)))\n",
    "        db = (1/N)*(np.sum(dZ, axis=1, keepdims=True))\n",
    "        grads[\"dW%i\" %(l)] = dW\n",
    "        grads[\"db%i\" %(l)] = db\n",
    "    \n",
    "    return grads\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function for updating parameters based on gradients\n",
    "def update_parameters_NN(params, grads, learning_rate, L):\n",
    "    'L is the number of layers in NN'\n",
    "    for i in range(1, L+1, 1):\n",
    "        l = i # l denotes layer number\n",
    "        params[\"W%i\" %(l)] = params[\"W%i\" %(l)] - learning_rate*grads[\"dW%i\" %(l)]\n",
    "        params[\"b%i\" %(l)] = params[\"b%i\" %(l)] - learning_rate*grads[\"db%i\" %(l)]\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is for predicting output given parameters(W, b for all layers) and X_test\n",
    "def predict_NN(params, X_test, L):\n",
    "    'L is the number of layers in NN'\n",
    "    A, cache = forward_propagation_NN(X_test, params, L)\n",
    "    \n",
    "    N = X_test.shape[1]\n",
    "    Y_prediction = np.argmax(A, axis=0)\n",
    "    Y_prediction = Y_prediction.reshape(Y_prediction.shape[0], 1)\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is for creating the final NN model\n",
    "# This model is for multi-class classification problem\n",
    "'''\n",
    "    Need to set:\n",
    "        L: number of layers in NN\n",
    "        n[i] for i=1:L-1: need to set number of units in each layer\n",
    "        n[L]: equal to number of classes in multiclass classification problem\n",
    "        n[0]: equal to number of dimensions of an input-sample\n",
    "        init_wt: set initial value of weights in weight matrix\n",
    "        init_b: set inital value of bias\n",
    "        learning_rate: need to set learning rate\n",
    "        num_iterations: need to set number of iterations of GD\n",
    "'''\n",
    "def L_layer_NN(X_train, Y_train, X_test, Y_test, learning_rate, num_iterations, L, n, init_wt, init_b):\n",
    "    cost_list = []\n",
    "    index_list = []\n",
    "    \n",
    "    # Number of samples\n",
    "    N_train = X_train.shape[1]\n",
    "    N_test = X_test.shape[1]\n",
    "    \n",
    "    # initiailze parameters and layer sizes\n",
    "    params = init_params_and_layer_sizes_NN(X_train, Y_train, L, n, init_wt, init_b)\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "        # forward propagation\n",
    "        A, cache = forward_propagation_NN(X_train, params, L)\n",
    "        \n",
    "        # compute cost\n",
    "        cost = compute_cost_NN(A, Y_train)\n",
    "        \n",
    "        # backward propagation\n",
    "        grads = backward_propagation_NN(params, cache, X_train, Y_train, L)\n",
    "        \n",
    "        # update parameters\n",
    "        params = update_parameters_NN(params, grads, learning_rate, L)\n",
    "        \n",
    "        # For plotting time vs cost graph\n",
    "        if i%1000 == 0:\n",
    "            cost_list.append(cost)\n",
    "            index_list.append(i)\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    # For plotting time vs cost graph\n",
    "    plt.plot(index_list, cost_list)\n",
    "    plt.xticks(index_list, rotation='vertical')\n",
    "    plt.xlabel(\"Number of Iteration\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "    \n",
    "    # predict\n",
    "    Y_prediction_test = predict_NN(params, X_test, L)\n",
    "    Y_prediction_train = predict_NN(params, X_train, L)\n",
    "    \n",
    "    # Print train/test Errors\n",
    "    Y_train_label = np.argmax(Y_train, axis=0)\n",
    "    Y_train_label = Y_train_label.reshape(Y_train_label.shape[0], 1)\n",
    "    \n",
    "    Y_test_label = np.argmax(Y_test, axis=0)\n",
    "    Y_test_label = Y_test_label.reshape(Y_test_label.shape[0], 1)\n",
    "    \n",
    "    print (\"train accuracy: {} %\".format(100 - (np.count_nonzero(Y_prediction_train - Y_train_label))*(100/N_train)))\n",
    "    print (\"test accuracy: {} %\".format(100 - (np.count_nonzero(Y_prediction_test - Y_test_label))*(100/N_test)))\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: -0.100000\n",
      "Cost after iteration 1000: -0.100003\n",
      "Cost after iteration 2000: -0.100004\n",
      "Cost after iteration 3000: -0.100006\n",
      "Cost after iteration 4000: -0.100012\n",
      "Cost after iteration 5000: -0.100024\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAEgCAYAAAAHeCwxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl8VOXd///XJwkECJuBAIGAgKAICBQioHexdWETBaxb+2sLtrbYWpfW+27VVqt16W3rt7cWa1utraLV2ioqVFBERIsLyCKyySaLhjUsRghbls/vjzmRScwGZuZkJu/n45FHZs5ync+J47w511xzHXN3REREEkFK2AWIiIjUlkJLREQShkJLREQShkJLREQShkJLREQShkJLREQShkIrzszsUjNbaWalZpZbR21eY2brzczNrG1dtCkiUh8ptOJvBfA14D912OZbwHnA5jpsU0Sk3lFoxZm7f+DuayouN7NUM7vXzBaa2TIzu+oY2nzP3TfVaaEiIvVQWtgFyGeuBArc/XQzSwfeMrNX3H1j2IWJiNQXCq0YMLNXgQ6VrPqFu0+rYrcRQD8zuyR43groaWYfAe9Xsc933H3hF6tWRCRxKLRiwN3PO47dDLjW3WdVsq7vFyxJRCQp6DOt+mMW8EMzawRgZiebWUbINYmI1CsKrTgzs4vMLA84A5hhZmVXVo8Aq4AlZrYCeIhaXgmb2XVBmznAMjN7JAali4iEznRrEhERSRS60hIRkYShgRh1rG3btt61a9ewyxARSSiLFy/e5e5ZNW2n0KpjXbt2ZdGiRWGXISKSUMysVjP6qHtQREQShkJLREQShkJLREQShkJLREQShkJLREQSRqihZWajzGxNcAPDmypZn25m/wzWLzCzrlHrbg6WrzGzkTW1aWbdgjbWBW02Pt5jiIhIOEILLTNLBR4ERgO9gW+YWe8Km10J7HX3HsB9wG+CfXsDXwf6AKOAPwb3o6quzd8A97l7T2Bv0PYxH6Nu/woiInIswrzSGgysd/cN7n4EeBoYV2GbccCU4PGzwLlmZsHyp939cHC/qfVBe5W2GexzTtAGQZvjj/MYMfHIvA387pU1bNxVGKtDiIgkvDBDqxPwcdTzvGBZpdu4ezFQALSpZt+qlrcBPgnaqHisYz3G55jZJDNbZGaL8vPzqz3pqqzZvo8H567n7P/3Ohf/6W2eWvARBQeLjqstEZFkFWZoWSXLKs7eW9U2dbX8eI7x+YXuD7t7rrvnZmXVOAtJpe69tD9v33QuN43uRcHBIn7+/HJOv/tVrnlqCXPX7KS4pPS42hURSSZhTuOUB3SOep4DbK1imzwzSyNyN989Nexb2fJdQGszSwuupqK3P55jxESHVk34wVdO4qqzurMsr4CpS/KY/v5WXly2jawW6Vz0pU5cPDCHUzq0iGUZIiL1VphXWguJ3E6+WzCS7+vA9ArbTAcmBo8vAV7zyL1UpgNfD0b+dQN6Au9W1Wawz9ygDYI2px3nMWLOzOjfuTV3jOvLgp+fy5+/NZD+Oa3525sbGXn/f7jggXk8+tZG9hQeiUc5IiL1Rqj30zKz84H7gVTgb+5+t5ndASxy9+lm1gR4AvgSkaufr7v7hmDfXwDfBYqBH7v7S1W1GSzvTmRgRibwHvAtdz98PMeoTm5ursdqwtxd+w8zfelWpi7JY+XWT0lLMc7u1Y5LBuVw9intaJymr92JSGIys8XunlvjdroJZN2KZWhFW739U6YuzuP597aya/9hTmjWiHEDIt2HfTu1JDIAUkQkMSi0QhKv0CpTXFLKvHW7eHZJHrNX7eBIcSknt2/OxQNzuOhLnWjXskncahEROV4KrZDEO7SiFRwo4t/LtvLckjyWfPQJKQbDemZx8aAcRvRuT5NG+m60iNRPCq2QhBla0T7M389zS/J4fskWthYcokWTNC7ol83FA3MYdOIJ6j4UkXpFoRWS+hJaZUpLnXc27Gbq4jxeWrGdg0UldG3TjK8NzOFrAzuRc0KzsEsUEVFohaW+hVa0/YeLeWn5NqYuyWP+hj0AnNG9DRcPymF03w5kpIf5tT0RacgUWiGpz6EV7eM9B3j+vS1MXZLH5t0HaNY4lVF9O3DJwByGdm9DSoq6D0UkfhRaIUmU0Crj7izevJepS/J48f1t7DtcTKfWTSOzbwzKoVvbjLBLFJEGQKEVkkQLrWiHikp4ZdUOpi7OY966fEodBnZpzcWDcrigX0daNW0UdokikqQUWiFJ5NCKtuPTQ5Huw8V5rNu5n8ZpKQzv3Z5LBuYwrGdb0lI1+4aI1B2FVkiSJbTKuDvLtxQwdXFk8t69B4rIapHO+AEduXhQDr06tAy7RBFJAgqtkCRbaEU7UlzKa6t3MnVJHnNX76S41OnbqSUXD8xhbP+OtGmeHnaJIpKgFFohSebQirZ7/2Gmvx+ZvHfFlqOT9148MIdzemnyXhE5NgqtkDSU0Iq2evunPLdkC8+/t4X8fZHJe8f2j3QfntaplWbfEJEaKbRC0hBDq0xlk/f2bNeciwdFJu9tr8l7RaQKCq2QNOTQilZwoIgXl29l6uKjk/d+uWcWFw/sxMg+HTR5r4iUo9AKiULr8zbk7+e5JVt4bkleZPLe9DTG9Mvm4kE55GryXhFBoRUahVbVSkud+Rt28+ySPF5aHpm8t3l6Gt3aZtA9K4PubZtHfmdl0K1tBs0aay5EkYZCoRUShVbtFB4uZtbK7SzLK+DD/P1syC9ka8FBol+O2a2alAuzbm0zOCmrOR1bNyVVcyOKJBWFVkgUWsfvUFEJm3YXsiG/kA1BkG3YFXn86aHiz7ZrnJZCtzZHr8i6Z0VC7aS2zWnVTFNNiSSi2oaW+l+k3mjSKJVeHVp+bpYNd2d34ZGjYbYrEmxrduxj9qodFJce/YdXm4zGR7sbs5rTPQi1LpnN9N0xkSSg0JJ6z8xo2zydts3TGdwts9y6opJSPt5zgA35hWzcVciGXfv5ML+Q11bn869FeZ9tl5pidD6habkgi3Q3ZpDVIl2DQUQShEJLElqj1JSge7D559Z9eqiIjfmRIItcpRXyYf5+3v5wF4eKSj/brkV6Gt2yMujeNoNuGgwiUq/p/0hJWi2bNKJ/59b079y63PLSUmfbp4eOfm4WdDku3LSXae9vLTcYpGOrJkGgNS/X5ajBICLhUGhJg5OSYnRq3ZROrZsyrGdWuXWHikoi3YxBmG3cVciHuwp5YekW9lUxGKRshGM3DQYRiTmFlkiUJo1SOTW7Jadmf34wyK79Rz4LsrJRjWu2Vz4YJDrINBhEpO4otERqwczIapFOVot0hnRvU25d9GCQ6M/P5qzewa5FRz7bLjXF6JLZjCHdMjn/tGzOOKkNjXQzTZFjotAS+YLKDwZpX25dwcGioLsxEmZrd+zj3+9v5emFH3NCs0aM7NOBMf2yOaN7G90NWqQWFFoiMdSqaSMGdG7NgKjBIIeKSnhjbT4zlm0rF2Cj+naIXIEpwESqpBkx6phmxJBjcaiohNfX5DNz+TbmfLCDwiMlZGY0ZmSf9gowaVA0jVNIFFpyvKID7NUPdnDgswDrwJjTshnaPVMBJklLoRUShZbUhUiA7WTG8u3MUYBJA6DQColCS+padQF2Qb9shnRTgEniU2iFRKElsXTwSAlvrN3Ji8u28drqnRw4UkKbjMaM7Bu5AlOASaKq16FlZpnAP4GuwCbgMnffW8l2E4Fbgqd3ufuUYPkg4DGgKTATuN7dvap2LTIb6u+B84EDwBXuvqSGY7wOZAMHg3Uj3H1nTeem0JJ4OXik7ApsG3M+2MnBoqMBdsFp2QxWgEkCqe+h9Vtgj7vfY2Y3ASe4+40VtskEFgG5gAOLgUFBCL0LXA/MJxJak939paraNbPzgWuJhNYQ4PfuPqSGY7wO/I+7H1MCKbQkDGUB9uLybbwWFWCjgiswBZjUd/X9flrjgK8Gj6cArwM3VthmJDDb3fcAmNlsYFQQJi3d/Z1g+ePAeOClatodBzzukYSeb2atzSw72PZzxwD+UZcnKxJrTRunMvq0bEafls3BIyXMDa7AnluyhScXfETb5kcHcQzp3kaT/UrCCiu02rv7NgB332Zm7SrZphPwcdTzvGBZp+BxxeXVtVtdW5UtL/OomZUAU4l0HVZ6WWpmk4BJAF26dKn0hEXipWnjVM4/LZvzqwmwsi8yD+mmAJPEErPQMrNXgQ6VrPpFbZuoZJlXs7yu2/qmu28xsxZEQuvbwOOVNe7uDwMPQ6R7sIZaROImOsAOHClm7urI98CmLt7C3+d/RNvm6Yzq214BJgkjZqHl7udVtc7MdphZdnA1lA1UNsAhj6NdfQA5RLr78oLH0cu3Bo+rajcP6FzJPlUdA3ffEvzeZ2ZPAYOpIrREEkGzxmmM6ZfNmH7lA+zZxXnlAmzMaR0Z3C1TASb1Uljdg9OBicA9we9plWwzC/i1mZ0QPB8B3Ozue8xsn5kNBRYAE4AHamh3OnCNmT1NZCBGQRBslR7DzNKA1u6+y8waARcAr9bVyYuErbIAm7F8a7kAGx10ISrApD4Ja/RgG+BfQBfgI+DSIIxygR+4+/eC7b4L/DzY7W53fzRYnsvRIe8vAdcGQ96rateAPxAZZHEA+E7ZqMDKjmFmGcB/gEZAKpHAusHdS2o6N40elER24Egxr63eyczlke+BHSoq/SzAxvTL5vSuCjCJjXo95D2ZKbQkWRQeLo4M4li2jblrIgGW1eLoFZgCTOqSQiskCi1JRoWHj16BKcAkFhRaIVFoSbIrC7CyK7DDxZEAOz8IsFwFmBwHhVZIFFrSkBQeLmbO6p3MjAqwdlFXYAowqS2FVkgUWtJQVRVg55+WzVVf6U52q6Zhlyj1mEIrJAotEdj/WRfiVuauySejcSr/d9kAzu5V2eQ3IrUPLc2gKSJ1rnl6GmP7d+Shb+fy8vXD6NCqKd95bCH/O/MDikpKwy5PEphCS0RiqntWc56/+ky+OaQLD/1nA5c/9A5bPjlY844ilVBoiUjMNWmUyt0XncYD3/gSa3fsZ8zkecz5YEfYZUkCUmiJSNxc2L8jL177ZTq1bsqVUxZx94xV6i6UY6LQEpG46to2g6k/PJNvDz2Rv8zbyGUPvUPe3gNhlyUJQqElInHXpFEqd47vy4P/30DW7djPmMlvMnuVugulZgotEQnNmH7ZzLjuy3TObMr3H1/EXS+u4kixugulagotEQnViW0i3YVXnNmVR97cyKUPvcPHe9RdKJVTaIlI6NLTUrl9bB/+9M2BbNgZGV04a+X2sMuSekihJSL1xujTsplx3TC6ts3gqicW86t/r1R3oZSj0BKReqVLm2Y884MzuOLMrjz61iYu/fPb6i6Uzyi0RKTeKesu/PO3BrJhVyHnT57Hyyu2hV2W1AMKLRGpt0b1zWbmdcPo3jaDH/x9CbdPX8nh4pKwy5IQKbREpF7rnNmMZ35wJt/9r2489vYmLvnTO3y0W92FDZVCS0TqvcZpKfzywt489O1BbN5dyJjJ85i5XN2FDZFCS0QSxsg+HZhx3TBOatecq59cwi+nreBQkboLGxKFlogklM6ZzfjXVWfw/WHdePydzVz8p7fZtKsw7LIkThRaIpJwGqel8IsxvfnLhFzy9h7kggfe5MVlW8MuS+JAoSUiCWt47/bMuO7L9GzfnGueeo9bXliu7sIkp9ASkYSWc0Kku3DSWd35+/yP+Nof32ajuguTlkJLRBJeo9QUfn7+qfztily2FhzkgsnzmP6+uguTkUJLRJLGOb3aM/O6YfTKbsl1/3iPnz+v7sJko9ASkaTSsXVTnp40lKu+0p2nFnzERX98mw35+8MuS+qIQktEkk6j1BRuHn0qj15xOtsLDnLhA28ybemWsMuSOqDQEpGkdXavdsy8fhinZrfk+qeXcvNzy9RdmOAUWiKS1LJbRboLr/7qSfzj3Y8Z/+BbrN+p7sJEpdASkaSXlprCz0b14rHvnM7OfYcZ+4c3eeE9dRcmolBCy8wyzWy2ma0Lfp9QxXYTg23WmdnEqOWDzGy5ma03s8lmZtW1axGTg+2XmdnAqLZeNrNPzOzFCsfuZmYLgrb+aWaNY/PXEJF4+eop7Zh53TD6dmzFj/+5lBufXcbBI+ouTCRhXWndBMxx957AnOB5OWaWCdwGDAEGA7dFhdufgElAz+BnVA3tjo7adlKwf5l7gW9XUuNvgPuCtvYCVx7XmYpIvdKhVROe+v4Qrjm7B/9aXNZduC/ssqSWwgqtccCU4PEUYHwl24wEZrv7HnffC8wGRplZNtDS3d9xdwcej9q/qnbHAY97xHygddAO7j4HKPeKDa7czgGeraFGEUlAaakp/M/IU5jyncHs2n+YCx94i6mL88IuS2ohrNBq7+7bAILf7SrZphPwcdTzvGBZp+BxxeXVtVtVW1VpA3zi7sW12d7MJpnZIjNblJ+fX02zIlKfnHVyFjOvH0a/nFb89zPv89Nn3ld3YT0Xs9Ays1fNbEUlP+Nq20Qly7ya5cfTVp1s7+4Pu3uuu+dmZWXVUIqI1CftWzbhye8N4dpzevDskjzGPfgm63aou7C+illouft57t63kp9pwI6y7rng985KmsgDOkc9zwG2BstzKllONe1W1VZVdhHpQkyr5fYiksDSUlP47xGn8Ph3B7On8Ahj//AWzyz6uOYdJe7C6h6cDpSNBpwITKtkm1nACDM7IRiAMQKYFXT77TOzocFnTxOi9q+q3enAhGAU4VCgoKwbsTLBZ2VzgUtqqFFEksiwnlnMvG4Y/Tu34qfPLuO///U+B44U17yjxE1YoXUPMNzM1gHDg+eYWa6ZPQLg7nuAO4GFwc8dwTKAHwKPAOuBD4GXqmsXmAlsCLb/C3B1WSFmNg94BjjXzPLMbGSw6kbgBjNbT+Qzrr/W6V9AROqldi2b8OT3hnL9uT157r08xv7hLdaqu7DesMhFhdSV3NxcX7RoUdhliEgdeGv9Lq5/ein7Dxdxx7i+XDooh+BroVLHzGyxu+fWtJ1mxBARqcJ/9WjLzOu/zMAuJ/CzoLuw8LC6C8Ok0BIRqUa7Fk144soh/OS8k3l+6RbG/uFNVm//NOyyGqxahZaZPVGbZSIiySg1xbj+vJ48+b0hfHqomHF/eIt/LvwIfbwSf7W90uoT/cTMUoFBdV+OiEj9deZJbZl53TBO75rJjVOX85N/LlV3YZxVG1pmdrOZ7QP6mdmnwc8+It9/0hBwEWlwslqkM+W7g7lh+MlMf38rFz7wJh9sU3dhvFQbWu7+v+7eArjX3VsGPy3cvY273xynGkVE6pXUFOO6c3vy1PeHsv9wMeMffIunFqi7MB5q2z34opllAJjZt8zs/8zsxBjWJSJS7w3t3oaZ1w9jcLdMfv788mB4vLoLY6m2ofUn4ICZ9Qd+BmwmMru6iEiD1rZ5OlO+M5ifjjyFF5dFugtXbVV3YazUNrSKg6mNxgG/d/ffAy1iV5aISOJISTF+dHYP/vH9oRw4Usz4P77F4s17wy4rKdU2tPaZ2c1EbpY4Ixg92Ch2ZYmIJJ4h3dsw87phtM1ozC+eX05xSWnYJSWd2obW5cBh4Lvuvp3IvaXujVlVIiIJqk3zdH55YR9Wb9/HY29vCrucpFOr0AqC6kmglZldABxyd32mJSJSiZF92nP2KVncN3st2wsOhV1OUqntjBiXAe8ClwKXAQvM7JLq9xIRaZjMjNvH9qGo1Llzxqqwy0kqte0e/AVwurtPdPcJwGDg1tiVJSKS2E5sk8GPvtqDGcu28Z+1+WGXkzRqG1op7h59d+Hdx7CviEiDdNVXutO1TTNum76Sw8UlYZeTFGobPC+b2Swzu8LMrgBmELmxooiIVKFJo1TuGNeXjbsKefiNDWGXkxRqmnuwh5n9l7v/FHgI6Af0B94BHo5DfSIiCe2sk7MYc1o2f5i7no92Hwi7nIRX05XW/cA+AHd/zt1vcPefELnKuj/WxYmIJINbL+hNWopx2/QVmp/wC6optLq6+7KKC919EdA1JhWJiCSZDq2a8JPhJzN3TT6vrNoRdjkJrabQalLNuqZ1WYiISDKbeGZXTmnfgl9NX8mBI5pU93jVFFoLzez7FRea2ZXA4tiUJCKSfBqlpnDXRX3ZWnCIyXPWh11OwkqrYf2PgefN7JscDalcoDFwUSwLExFJNqd3zeSSQTk8Mm8DFw/sRM/2mnf8WNV0E8gd7n4m8CtgU/DzK3c/I5jaSUREjsHNo3uRkZ7GrdM0KON41Hbuwbnu/kDw81qsixIRSVZtmqfzs1GnMH/DHqYt3Rp2OQlHs1qIiMTZ10/vQv/OrblrxgcUHCwKu5yEotASEYmz1BTjrnF92VN4mP97ZU3Y5SQUhZaISAhOy2nFt4eeyBPzN7M8ryDschKGQktEJCQ3jDiFzIx0bpm2gtJSDcqoDYWWiEhIWjVtxC/G9OL9jz/h6YUfh11OQlBoiYiEaPyATgzplslvXl7N7v2Hwy6n3lNoiYiEyMy4a3xfCg8Xc89Lq8Mup95TaImIhKxn+xZ8b1h3nlmcx8JNe8Iup15TaImI1APXnduDjq2acMvzKygqKQ27nHorlNAys0wzm21m64LfJ1Sx3cRgm3VmNjFq+SAzW25m681ssplZde1axORg+2VmNjCqrZfN7BMze7HCsR8zs41mtjT4GRCbv4aICDRrnMZtY/uwZsc+pry9Kexy6q2wrrRuAua4e09gTvC8HDPLBG4DhgCDgduiwu1PwCSgZ/AzqoZ2R0dtOynYv8y9wLerqPOn7j4g+Fl6PCcqIlJbI3q355xe7bhv9lq2FxwKu5x6KazQGgdMCR5PAcZXss1IYLa773H3vcBsYJSZZQMt3f0dj8w2+XjU/lW1Ow543CPmA62DdnD3OQR3ZxYRCZOZcfuFfSgude6csSrscuqlsEKrvbtvAwh+t6tkm05A9BcX8oJlnYLHFZdX125VbdXk7qA78T4zS69qIzObZGaLzGxRfn5+LZoVEalclzbN+NHZPZixbBv/Wav3k4piFlpm9qqZrajkZ1xtm6hkmVez/Hjaqs7NQC/gdCATuLGqDd39YXfPdffcrKysGpoVEanepLO6061tBr+ctoJDRSVhl1OvxCy03P08d+9byc80YEdZ91zwe2clTeQBnaOe5wBbg+U5lSynmnaraqu6+rcF3YmHgUeJfK4mIhJzTRql8quxfdi0+wAP/2dD2OXUK2F1D04HykYDTgSmVbLNLGCEmZ0QDMAYAcwKuv32mdnQYNTghKj9q2p3OjAhGEU4FCgo60asSlT4GZHPxlYcx3mKiByXs07OYky/bP4wdz2bdxeGXU69EVZo3QMMN7N1wPDgOWaWa2aPALj7HuBOYGHwc0ewDOCHwCPAeuBD4KXq2gVmAhuC7f8CXF1WiJnNA54BzjWzPDMbGax60syWA8uBtsBddfoXEBGpwa1jetMoxbh9+krd5Thg+kPUrdzcXF+0aFHYZYhIknhk3gbumvEBf/7WIEb17RB2OTFjZovdPbem7TQjhohIPXbFmV3p1aEFd/x7JQeOFIddTugUWiIi9Vhaagp3ju/L1oJDTJ6zPuxyQqfQEhGp507vmsmlg3J4ZN4G1u1o2HMhKLRERBLATaN7kZGexi0vrGjQgzIUWiIiCaBN83RuHNWLBRv38MLSLWGXExqFlohIgvj66Z3p37k1d8/4gIKDRWGXEwqFlohIgkhJMe4e35c9hUf43Strwi4nFAotEZEE0rdTKyac0ZW/z9/M8ryCsMuJO4WWiEiCuWHEyWRmpHPLC8spKW1YgzIUWiIiCaZlk0bcMuZU3s8r4OmFH4VdTlwptEREEtC4AR0Z2j2T3768hl37D4ddTtwotEREEpCZcdf4vhQeLuael1aHXU7cKLRERBJUj3Yt+P5Z3Xl2cR7vbtxT8w5JQKElIpLArj2nB51aN+XWF1ZQVFIadjkxp9ASEUlgzRqncduFvVmzYx9T3t4Udjkxp9ASEUlww3u355xe7bhv9lq2FRwMu5yYUmiJiCQ4M+P2C/tQXOrc9eIHYZcTUwotEZEk0KVNM645uwczlm/jjbX5YZcTMwotEZEkMekr3enWNoPbpq3gUFFJ2OXEhEJLRCRJpKelcse4PmzafYCH3tgQdjkxodASEUkiw3pmcUG/bB58fT2bdxeGXU6dU2iJiCSZWy/oTePUFG6fvjLp7nKs0BIRSTLtWzbhJ8NPZu6afGat3BF2OXVKoSUikoQmnnEivTq04I5/r6TwcHHY5dQZhZaISBJKS03hrvF92VpwiMmvrQu7nDqj0BIRSVK5XTO5LDeHv87byNod+8Iup04otEREkthNo0+leZM0bnlhRVIMylBoiYgkscyMxtw4qhfvbtzD8+9tCbucL0yhJSKS5C7P7cyAzq359cwPKDhYFHY5X4hCS0QkyaWkRO5yvKfwCL97ZU3Y5XwhCi0RkQagb6dWTDijK0/M38zyvIKwyzluCi0RkQbihhEn0yYjnVteWE5JaWIOylBoiYg0EC2bNOLWC07l/bwC/vHuR2GXc1xCCS0zyzSz2Wa2Lvh9QhXbTQy2WWdmE6OWDzKz5Wa23swmm5lV165FTA62X2ZmA4PlA8zsHTNbGSy/POoY3cxsQdDWP82scWz/KiIisTe2f0fO6N6G3768ml37D4ddzjEL60rrJmCOu/cE5gTPyzGzTOA2YAgwGLgtKtz+BEwCegY/o2pod3TUtpOC/QEOABPcvU/Qxv1m1jpY9xvgvqCtvcCVdXDeIiKhMjPuHN+Hg0Ul/O/M1WGXc8zCCq1xwJTg8RRgfCXbjARmu/sed98LzAZGmVk20NLd3/HIN+Uej9q/qnbHAY97xHygtZllu/tad18H4O5bgZ1AVnDldg7wbA01iogknB7tWvD9Yd2ZuiSPdzfuCbucYxJWaLV3920Awe92lWzTCfg46nlesKxT8Lji8uraraqtz5jZYKAx8CHQBvjE3Yur2r7CvpPMbJGZLcrPT97bXItI8rj2nJ50at2UW19YQVFJadjl1FrMQsvMXjWzFZX8jKttE5Us82qWH09bZbVmA08A33H30mM9hrs/7O7e+oAAAAAOVUlEQVS57p6blZVVQykiIuFr2jiV28f2Yc2OfTz21qawy6m1tFg17O7nVbXOzHYE3XPbgsDYWclmecBXo57nAK8Hy3MqLN8aPK6q3Tygc2X7mFlLYAZwS9B1CLCLSBdiWnC1FX0MEZGkMLx3e87t1Y77Xl3LBf2zyW7VNOySahRW9+B0oGw04ERgWiXbzAJGmNkJwQCMEcCsoNtvn5kNDT57mhC1f1XtTgcmBKMIhwIFQbA1Bp4n8nnXM2UHDj4rmwtcUkONIiIJ7faxfSgpde58cVXYpdRKWKF1DzDczNYBw4PnmFmumT0C4O57gDuBhcHPHcEygB8CjwDriXwG9VJ17QIzgQ3B9n8Brg6WXwacBVxhZkuDnwHBuhuBG8xsPZHPuP5at38CEZHwdc5sxrXn9GDm8u28vqayTq/6xZJhqvr6JDc31xctWhR2GSIitXa4uITR98+jxJ1ZPz6LJo1S416DmS1299yattOMGCIiDVx6Wip3jOvL5t0HeOiNDWGXUy2FloiI8OWebbmwf0cefH09m3cXhl1OlRRaIiICwC1jTqVxagq/nLay3t7lWKElIiIAtG/ZhJ8MP5k31uYza+X2sMuplEJLREQ+M/GME+nVoQW/+vcqCg8X17xDnCm0RETkM2mpKdx9UV+2FRxi8px1YZfzOQotEREpZ9CJmVye25m/vrmRtTv2hV1OOQotERH5nBtH96J5kzRueWFFvRqUodASEZHPycxozE2jevHuxj08/96WsMv5jEJLREQqdVluZ77UpTW/nvkBBQeKwi4HUGiJiEgVUlKMu8b3ZU/hEf7fK2vCLgdQaImISDX6dGzFhDO68vcFm1mW90nY5Si0RESkejeMOJm2zdO55YUVlJSGOyhDoSUiItVq2aQRt4w5lWV5BTz17keh1qLQEhGRGo3t35EzT2rDvS+vZtf+w6HVodASEZEamRl3jOvLwaIS/nfm6tDqUGiJiEit9GjXnElndWfqkjwWbNgdSg0KLRERqbVrzu5Jp9ZNuXXaCopKSuN+fIWWiIjUWtPGqdw+tg9rd+zn0bc2xv34Ci0RETkmw3u357xT23H/q+vY+snBuB5boSUiIsfstgv7UOrOnS+uiutxFVoiInLMOmc249pzevLSiu28vmZn3I6r0BIRkePyvWHd6J6VwW3TV3KoqCQux1RoiYjIcUlPS+XOcX3ZvPsAf37jw7gcU6ElIiLH7b96tGVs/4788fUP2bSrMObHS4v5EUREJKndMuZUWjZNo2XTRjE/lkJLRES+kHYtm3DX+NPicix1D4qISMJQaImISMJQaImISMJQaImISMJQaImISMJQaImISMJQaImISMJQaImISMIwdw+7hqRiZvnA5uPcvS2wqw7LSQQ654ZB55z8vuj5nujuWTVtpNCqR8xskbvnhl1HPOmcGwadc/KL1/mqe1BERBKGQktERBKGQqt+eTjsAkKgc24YdM7JLy7nq8+0REQkYehKS0REEoZCS0REEoZCS0REEobuXBwiM+sFjAM6AQ5sBaa7+wehFiYiUk9pIEZIzOxG4BvA00BesDgH+DrwtLvfE1ZtUrfMrBUwivL/OJnl7p+EWliMmJkBgyl/vu96Er/ZNNBzDuV1rdAKiZmtBfq4e1GF5Y2Ble7eM5zKYqsBvoFPAG4DXgG2BItzgOHAr9z98bBqiwUzGwH8EVhH+fPtAVzt7q+EVVusNNBzDu11rdAKiZmtBka6++YKy08EXnH3U8KpLHYa2hs4gJmtAYZUDGUzOwFY4O4nh1NZbJjZB8Bod99UYXk3YKa7nxpKYTHUQM85tNe1PtMKz4+BOWa2Dvg4WNaFyL/Orgmtqtj6BTCoqhc6kHShBRiRK8qKSoN1ySaNo93d0bYAjeJcS7w0xHMO7XWt0AqJu79sZidztB/ciLzwF7p7SajFxU5DewMHuBtYYmavUP4fJ8OBO0OrKnb+Biw0s6c5er6diXxW+9fQqoqthnjOob2u1T0ocWNmE4FfEuke/NwL3d0fC6m0mAquJEdS/h8ns9x9b6iFxYiZ9QbGUv58p7v7qlALi6EGes6hvK4VWhJXDe0NvIyZtSdq8Im77wi5pJgzs0zAk/2/bbSGds5hvK4VWhJ3DekN3MwGAH8GWhEJaCMy+OQTIiPLloRYXp0zsy7Ab4FzgIJgcSvgNeCmioMVkkEDPefQXtcKLYmbhvYGDmBmS4Gr3H1BheVDgYfcvX84lcWGmb0D3A88W/bZrJmlApcCP3b3oWHWFwsN9JxDe10rtCRuGtobOICZravqO3dmtt7de8S7pliq4XyrXJfIdM6fWxfT17VGD0o8ZVQMLAB3n29mGWEUFAcvmdkMIsP5o0eWTQBeDq2q2FlsZn8EplD+fCcC74VWVWw1xHMO7XWtKy2JGzObDJxE5S/0je6elN9PM7PRHJ1jMnpk2cxQC4uBYEaXK6nkfIG/uvvhEMuLiYZ4zhDe61qhJXHVkN7ARaTuKbREYiiYa/FmIkHdLli8E5gG3JNscy6aWRqRq47xlJ9fchqRq46ianZPSA30nEN7XSu0JG4a2hs4gJnNIjL0eYq7bw+WdQCuAM519+EhllfnzOwfREaDTqH83QsmApnufnlYtcVKAz3n0F7XCi2Jm4b2Bg6RiUWrmvy4unWJqobzXZtsEwSDzvlY1tUF3blY4qmru/+mLLAA3H17cO+wLiHWFUubzexnwReqgciXq4P7qX1czX6Jaq+ZXWpmn723mFmKmV0OJOssEQ3xnEN7XSu0JJ4a2hs4wOVAG+ANM9trZnuA14FM4LIwC4uRrwOXANvNbG1w37jtwNeCdcmo7Jx3BOe8juQ/59Be1+oelLgJ5h28ifKfae0gMjT4nmSdr83MehH5jGO+u++PWj7K3ZPuu1pmNoTIYIQPgVOBocCqhjBC1MzaEBkVe7+7fyvseuLFzIYRuWPF8ljf9FKhJfWCmX3H3R8Nu466ZmbXAT8CPgAGANe7+7Rg3RJ3HxhmfXXNzG4DRhOZuGA2kTeyN4DziEyMfHeI5cWEmU2vZPE5RD6/xd3Hxrei2DOzd919cPD4e0Re4y8AI4B/B13+sTm2QkvqAzP7yN2T7nMtM1sOnOHu+82sK/As8IS7/97M3nP3L4VaYB0LzncAkE6kiyzH3T81s6ZE7mjbL9QCY8DMlgCrgEeIXGEa8A+CrkF3fyO86mIj+rVrZguB8909P5jZZr67nxarY2saJ4kbM1tW1SqgfRXrEl1qWZegu28ys68Cz5rZiSTnjS+Lg0ljD5jZh+7+KYC7HzSz0pBri5Vc4Hoid+b+qbsvNbODyRhWUVKC7v4UIhc/+QDuXmhmxbE8sEJL4qk9kXtpVfzsyoC3419OXGw3swHuvhQguOK6gMjdbmP2r9EQHTGzZu5+ABhUtjD4jl5Shpa7lwL3mdkzwe8dJP97aytgMcHdyM2sg7tvN7PmxPgfY8n+h5X65UWgedkbeDQzez3+5cTFBKDcvzzdvRiYYGYPhVNSTJ1VNtde8GZephGRL9smLXfPAy41szHAp2HXE0vu3rWKVaXARbE8tj7TEhGRhKHvaYmISMJQaImISMJQaInUkpm5mf0u6vn/mNntddT2Y2Z2SV20VcNxLjWzD8xsboXlXc1sRfB4gJmdX4fHbG1mV0c972hmz9ZV+9KwKLREau8w8DUzaxt2IdHMLPUYNr8SuNrdz65mmwHAMYVWcHuOqrQGPgstd9/q7jEPaElOCi2R2isGHgZ+UnFFxSslM9sf/P6qmb1hZv8K5qW7x8y+aWbvmtlyMzspqpnzzGxesN0Fwf6pZnavmS00s2VmdlVUu3PN7ClgeSX1fCNof4WZ/SZY9kvgy8Cfzezeyk7QInfhvQO43MyWmtnlZpZhZn8LanjPzMYF215hZs+Y2b+BV8ysuZnNMbMlwbHHBc3eA5wUtHdvhau6Jmb2aLD9e2Z2dlTbz5nZy2a2zsx+W+v/SpLUNORd5Ng8CCw7xjfR/kTm4NsDbAAecffBZnY9cC3w42C7rsBXgJOAuWbWg8iQ+QJ3P93M0oG3zKxsbrfBQF933xh9MDPrCPyGyPek9hIJlPHufoeZnQP8j7svqqxQdz8ShFuuu18TtPdr4DV3/66ZtQbeNbNXg13OAPq5+57gauuiYAaMtsD8YIqjm4I6BwTtdY065I+C455mkTkaXzGzslt5DAC+ROQKd42ZPeDuyTqxstSSrrREjkEww8PjwHXHsNtCd98WfH/pQ6AsdJYTCaoy/3L3UndfRyTcehGZy22CmS0FFhCZWbtnsP27FQMrcDrwurvnB98JexI46xjqrWgEcFNQw+tAE47eSma2u+8JHhvw62Dmk1eJ3MW3pplOvgw8AeDuq4HNQFlozXH3Anc/RGSapBO/wDlIktCVlsixux9YAkRP8FtM8I9AMzOgcdS6w1GPS6Oel1L+/8GKX5osm8fuWnefFb0imA6qsIr66npGAgMudvc1FWoYUqGGbwJZwCB3LzKzTUQCrqa2qxL9dytB71eCrrREjllwZfEvIoMaymzi6LRF44jMAHGsLrXIzQNPAroDa4BZwA/NrBGAmZ1skUlJq7MA+IqZtQ0GaXyDyEzrtbUPaBH1fBZwbRDGmFlVk/y2AnYGgXU2R6+MKrYX7T9Ewo6gW7ALkfMWqZRCS+T4/A6IHkX4FyJB8S5Q8QqkttYQCZeXgB8E3WKPEOkaWxIMXniIGq443H0bcDMwF3gfWFJ2O5Ramgv0LhuIAdxJJISXBTXcWcV+TwK5ZraISBCtDurZTeSzuBWVDAD5I5Bqkdnh/wlcUTYNlEhlNI2TiIgkDF1piYhIwlBoiYhIwlBoiYhIwlBoiYhIwlBoiYhIwlBoiYhIwlBoiYhIwvj/AT8ULaNFv47aAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 6.973923590054582 %\n",
      "test accuracy: 7.748184019370456 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[-0.01504018,  0.01749645,  0.02385246, ..., -0.02828766,\n",
       "         -0.08562837,  0.015941  ],\n",
       "        [-0.01504018,  0.01749645,  0.02385246, ..., -0.02828766,\n",
       "         -0.08562837,  0.015941  ],\n",
       "        [-0.01504018,  0.01749645,  0.02385246, ..., -0.02828766,\n",
       "         -0.08562837,  0.015941  ],\n",
       "        ...,\n",
       "        [-0.01504018,  0.01749645,  0.02385246, ..., -0.02828766,\n",
       "         -0.08562837,  0.015941  ],\n",
       "        [-0.01504018,  0.01749645,  0.02385246, ..., -0.02828766,\n",
       "         -0.08562837,  0.015941  ],\n",
       "        [-0.01504018,  0.01749645,  0.02385246, ..., -0.02828766,\n",
       "         -0.08562837,  0.015941  ]]), 'b1': array([[-0.13942481],\n",
       "        [-0.13942481],\n",
       "        [-0.13942481],\n",
       "        [-0.13942481],\n",
       "        [-0.13942481],\n",
       "        [-0.13942481],\n",
       "        [-0.13942481],\n",
       "        [-0.13942481],\n",
       "        [-0.13942481],\n",
       "        [-0.13942481]]), 'W2': array([[0.8125128 , 0.8125128 , 0.8125128 , 0.8125128 , 0.8125128 ,\n",
       "         0.8125128 , 0.8125128 , 0.8125128 , 0.8125128 , 0.8125128 ],\n",
       "        [0.81274332, 0.81274332, 0.81274332, 0.81274332, 0.81274332,\n",
       "         0.81274332, 0.81274332, 0.81274332, 0.81274332, 0.81274332],\n",
       "        [0.81230058, 0.81230058, 0.81230058, 0.81230058, 0.81230058,\n",
       "         0.81230058, 0.81230058, 0.81230058, 0.81230058, 0.81230058],\n",
       "        [0.81313568, 0.81313568, 0.81313568, 0.81313568, 0.81313568,\n",
       "         0.81313568, 0.81313568, 0.81313568, 0.81313568, 0.81313568],\n",
       "        [0.81233235, 0.81233235, 0.81233235, 0.81233235, 0.81233235,\n",
       "         0.81233235, 0.81233235, 0.81233235, 0.81233235, 0.81233235],\n",
       "        [0.81254404, 0.81254404, 0.81254404, 0.81254404, 0.81254404,\n",
       "         0.81254404, 0.81254404, 0.81254404, 0.81254404, 0.81254404],\n",
       "        [0.81240248, 0.81240248, 0.81240248, 0.81240248, 0.81240248,\n",
       "         0.81240248, 0.81240248, 0.81240248, 0.81240248, 0.81240248],\n",
       "        [0.81236274, 0.81236274, 0.81236274, 0.81236274, 0.81236274,\n",
       "         0.81236274, 0.81236274, 0.81236274, 0.81236274, 0.81236274],\n",
       "        [0.81210576, 0.81210576, 0.81210576, 0.81210576, 0.81210576,\n",
       "         0.81210576, 0.81210576, 0.81210576, 0.81210576, 0.81210576],\n",
       "        [0.81247264, 0.81247264, 0.81247264, 0.81247264, 0.81247264,\n",
       "         0.81247264, 0.81247264, 0.81247264, 0.81247264, 0.81247264]]), 'b2': array([[-0.00024583],\n",
       "        [-0.02332484],\n",
       "        [ 0.01360076],\n",
       "        [-0.0572242 ],\n",
       "        [ 0.01263879],\n",
       "        [-0.00231564],\n",
       "        [ 0.00972305],\n",
       "        [ 0.00671929],\n",
       "        [ 0.0372884 ],\n",
       "        [ 0.00314022]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L_layer_NN(X_train, Y_train, X_test, Y_test, learning_rate, num_iterations, L, n, init_wt, init_b)\n",
    "n = np.array([4096, 10, 10])\n",
    "n = n.reshape((3, 1))\n",
    "L_layer_NN(X_train, Y_train, X_test, Y_test, 0.01, 6000, 2, n, 0.1, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
